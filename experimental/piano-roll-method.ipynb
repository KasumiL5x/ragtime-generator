{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Globals\n",
    "Let's first define some variables that are required throughout different stages.  Think of this like a configuration section.  Always run this as different sections may need some of them defining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution to sample at.  Must be consistent between all stages.\n",
    "SAMPLE_FREQ = 12\n",
    "# What is the highest note allowed? 108 is the top of an 88 key piano.  Must be consistent between all stages.\n",
    "HIGHEST_NOTE = 108\n",
    "\n",
    "# How far to search for END_KEY when converting back to midi.\n",
    "END_SEARCH_DIST = 50\n",
    "\n",
    "# The key that's used for waits.\n",
    "WAIT_KEY = 'wait'\n",
    "# The key that's used for ends.\n",
    "END_KEY = 'end'\n",
    "\n",
    "# Where are the source midi files located?\n",
    "MIDI_PATH = './data/midi/'\n",
    "# OUTPUT path for converted rolls.\n",
    "ROLL_PATH = './data/roll/'\n",
    "# Nested rolls array cache.\n",
    "ROLL_FILE = './notes.bin'\n",
    "\n",
    "# The width of the sliding window when generating X and y data.\n",
    "SEQUENCE_LENGTH = 128\n",
    "\n",
    "# The actual model checkpoint.\n",
    "MODEL_FILE = './model.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Conversion\n",
    "Firstly the source midi files need to be converted into a notewise format.  This is a preprocessing step that results in actual new files that will be used for the training process rather than having to ingest the midi files each time.  If these files already exist and don't need updating, then this should not need to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import music21 as m21\n",
    "\n",
    "def convert_midi_to_roll(file, sample_freq):\n",
    "    midi = m21.converter.parse(file)\n",
    "    \n",
    "    # Get all note pitches (in midi format), offsets, and durations.\n",
    "    notes = []\n",
    "    for el in midi.recurse():\n",
    "        if isinstance(el, m21.note.Note):\n",
    "            notes.append((el.pitch.midi, math.floor(el.offset * sample_freq), math.floor(el.duration.quarterLength * sample_freq)))\n",
    "        #end\n",
    "        \n",
    "        if isinstance(el, m21.chord.Chord):\n",
    "            for pitch in el.pitches:\n",
    "                notes.append((pitch.midi, math.floor(el.offset * sample_freq), math.floor(el.duration.quarterLength * sample_freq)))\n",
    "            #end\n",
    "        #end\n",
    "    #end\n",
    "    \n",
    "    # Create piano roll array.\n",
    "    max_timestep = math.floor(midi.duration.quarterLength * sample_freq) + 1\n",
    "    roll_array = np.zeros((max_timestep, HIGHEST_NOTE))\n",
    "    for note in notes:\n",
    "        pitch = note[0]\n",
    "        if pitch < 0 or pitch > HIGHEST_NOTE:\n",
    "            print(f'Ignoring out of range pitch: {pitch}')\n",
    "            continue\n",
    "        #end\n",
    "        roll_array[note[1], pitch] = 1 # Strike note.\n",
    "        roll_array[note[1] + 1:note[1] + note[2], pitch] = 2 # Hold note.\n",
    "    #end\n",
    "    \n",
    "    # Convert roll into strings.\n",
    "    roll_string = []\n",
    "    for ts in roll_array:\n",
    "        tmp = ''.join([str(int(n)) for n in ts])\n",
    "        roll_string.append(f'{tmp}')\n",
    "    #end\n",
    "    \n",
    "    # Convert roll strings into a notewise format.\n",
    "    notewise = []\n",
    "    for i in range(len(roll_string)):\n",
    "        curr = roll_string[i]\n",
    "        # Find the next matching value (or empty string if at the end).\n",
    "        nxt = '' if i == (len(roll_string)-1) else roll_string[i+1]\n",
    "        \n",
    "        for j in range(len(curr)):\n",
    "            if curr[j] == '0':\n",
    "                continue\n",
    "            #end\n",
    "            note = str(j)\n",
    "            if curr[j] == '1':\n",
    "                notewise.append(note)\n",
    "            if nxt == '' or nxt[j] == '0':\n",
    "                notewise.append(f'{END_KEY}{note}')\n",
    "        #end\n",
    "        \n",
    "        notewise.append(WAIT_KEY)\n",
    "    #end\n",
    "    \n",
    "    # Create the final string and merge all of the successive 'wait' values at the same time.\n",
    "    i=0\n",
    "    while i < len(notewise):\n",
    "        wait_count = 1\n",
    "        if WAIT_KEY == notewise[i]:\n",
    "            while (wait_count <= sample_freq * 2) and ((i + wait_count) < len(notewise)) and (WAIT_KEY == notewise[i + wait_count]):\n",
    "                wait_count += 1\n",
    "            #end\n",
    "            notewise[i] = WAIT_KEY + str(wait_count)\n",
    "        #end\n",
    "        i += wait_count\n",
    "    #end\n",
    "    \n",
    "    # Remove all redundant 'wait' entries.\n",
    "    notewise = list(filter(lambda x: x != WAIT_KEY, notewise))\n",
    "    \n",
    "    return ' '.join(notewise)\n",
    "#end\n",
    "\n",
    "def convert_roll_to_midi(roll, sample_freq, output_file):\n",
    "    speed = 1.0 / sample_freq\n",
    "    time_offset = 0\n",
    "    notes = []\n",
    "    \n",
    "    for i in range(len(roll)):\n",
    "        curr = roll[i]\n",
    "        \n",
    "        # Skip ends.\n",
    "        if END_KEY == curr[:3]:\n",
    "            continue\n",
    "        #end\n",
    "        \n",
    "        # Handle waits.\n",
    "        if WAIT_KEY == curr[:4]:\n",
    "            time_offset += int(curr[4:])\n",
    "            continue\n",
    "        #end\n",
    "        \n",
    "        duration = 1.0\n",
    "        has_end = False\n",
    "        curr_len = len(curr)\n",
    "        # Look ahead to find a matching end.\n",
    "        for j in range(1, END_SEARCH_DIST):\n",
    "            if (i+j) == len(roll):\n",
    "                break\n",
    "            #end\n",
    "            \n",
    "            if WAIT_KEY == roll[i+j][:4]:\n",
    "                duration += int(roll[i+j][4:])\n",
    "            #end\n",
    "            \n",
    "            if (END_KEY + curr) == roll[i+j][:3 + curr_len] or roll[i+j][:curr_len] == curr:\n",
    "                has_end = True\n",
    "                break\n",
    "            #end\n",
    "        #end\n",
    "        \n",
    "        if not has_end:\n",
    "            duration = sample_freq\n",
    "        #end\n",
    "        \n",
    "        try:\n",
    "            new_note = m21.note.Note(int(curr))\n",
    "            new_note.duration = m21.duration.Duration(duration * speed)\n",
    "            new_note.offset = time_offset * speed\n",
    "            notes.append(new_note)\n",
    "        except:\n",
    "            print(f'Unknown note: {curr}')\n",
    "    #end\n",
    "    \n",
    "    piano = m21.instrument.fromString('Piano')\n",
    "    notes.insert(0, piano)\n",
    "    stream = m21.stream.Stream(notes)\n",
    "    stream.timeSignature = m21.meter.TimeSignature('3/4')\n",
    "    stream.tempo = m21.tempo.MetronomeMark(number=80)\n",
    "    stream.keySignature = m21.key.KeySignature(0)\n",
    "    \n",
    "    stream.write('midi', fp=output_file)\n",
    "    curr_time = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "    print(f'{output_file} written at {curr_time}')\n",
    "#end\n",
    "\n",
    "# Testing!\n",
    "# convert_roll_to_midi(output, SAMPLE_FREQ, './output.mid')\n",
    "# convert_roll_to_midi(convert_midi_to_roll('../data/C_mapleaf.mid', SAMPLE_FREQ).split(' '), SAMPLE_FREQ, './output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# Just load the notes file if it already exists.\n",
    "if os.path.exists(ROLL_FILE):\n",
    "    print('Loading existing notes file...', end='')\n",
    "    with open(ROLL_FILE, 'rb') as file:\n",
    "        rolls = pickle.load(file)\n",
    "    #end\n",
    "    print('Done!')\n",
    "else:\n",
    "    # Make roll path if doesn't exist.\n",
    "    if not os.path.exists(ROLL_PATH):\n",
    "        os.makedirs(ROLL_PATH)\n",
    "    #end\n",
    "    \n",
    "    # Convert all midi files, save their text to a file, and append their text split by space to a nested list (one sublist per piece).\n",
    "    rolls = []\n",
    "    midi_files = glob.glob(MIDI_PATH + '*.mid') #[MIDI_PATH + 'C_mapleaf.mid']#\n",
    "    for midi_file in midi_files:\n",
    "        filename = os.path.basename(midi_file)\n",
    "        print(f'Processing `{filename}`...', end='')\n",
    "\n",
    "        try:\n",
    "            with open(ROLL_PATH + filename.split('.')[0] + '.txt', 'w') as file:\n",
    "                roll = convert_midi_to_roll(midi_file, SAMPLE_FREQ)\n",
    "                file.write(roll)\n",
    "                rolls.append(roll.split(' '))\n",
    "                print('done!')\n",
    "            #end\n",
    "        except:\n",
    "            print('failed!')\n",
    "    #end\n",
    "    # Save the combined rolls to a file to save having to process it in the future.\n",
    "    print('Writing binary pickle...', end='')\n",
    "    try:\n",
    "        with open(ROLL_FILE, 'wb') as file:\n",
    "            pickle.dump(rolls, file)\n",
    "            print('done!')\n",
    "        #end\n",
    "    except:\n",
    "        print('failed!')\n",
    "#end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Training\n",
    "Now let's take all of the processed files and create our `X` and `y` data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you haven't ran the first stage.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings\n",
    "Generate some mappings to go between unique notes and integers.  The integers are what will be used in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All notes flattened across rolls.\n",
    "flat_notes = [item for sublist in rolls for item in sublist]\n",
    "\n",
    "# All unique notes across all flattened rolls.\n",
    "unique_notes = sorted(set(flat_notes))\n",
    "\n",
    "# Build two dictionaries.  One maps notes (as strings) to ints, and the other backwards.\n",
    "# We use the first to convert the rolls into a sequence of integers, and the second to convert back to notes.\n",
    "note_to_int = dict((note, num) for num, note in enumerate(unique_notes))\n",
    "int_to_note = dict((num, note) for num, note in enumerate(unique_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X` and `y` data\n",
    "Building the training data using a sliding window.  Since the rolls are a nested list - one for each piece - I'm going to ensure that the sliding window does not go over a boundary (hence the nested lists).  Essentially, I'm creating `X` and `y` from sliding windows over different pieces joined together rather than treating the entire thing as one giant sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "# Apply a sliding window per piece but append the same data array.\n",
    "# This avoids a sliding window overlapping the boundaries between pieces.\n",
    "for roll in rolls:\n",
    "    for i in range(0, len(roll) - SEQUENCE_LENGTH):\n",
    "        # Snip a sequence of our piece as the X data of this window.\n",
    "        seq_in = roll[i:i + SEQUENCE_LENGTH]\n",
    "        data_X.append([note_to_int[n] for n in seq_in])\n",
    "        \n",
    "        # Take the next note as the y value to predict.\n",
    "        seq_out = roll[i + SEQUENCE_LENGTH]\n",
    "        data_y.append(note_to_int[seq_out])\n",
    "    #end\n",
    "#end\n",
    "\n",
    "# Create and shape the final X and y data for the network.\n",
    "X = np.reshape(data_X, (len(data_X), SEQUENCE_LENGTH, 1))\n",
    "X = X / float(len(flat_notes))\n",
    "y = np_utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "And now building the model.  It uses stacked LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "import keras.backend as K\n",
    "\n",
    "# A fresh start for use during debugging.\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and/or loading existing weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# A checkpoint to save the model.\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_FILE,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Load the model weights if they already exists.\n",
    "if os.path.exists(MODEL_FILE):\n",
    "    model.load_weights(MODEL_FILE)\n",
    "    print('Loaded existing weights...')\n",
    "#end\n",
    "\n",
    "# Should the training take place?\n",
    "should_train = True\n",
    "# How many epochs to train?\n",
    "train_epochs = 2\n",
    "# Batch size per epoch.\n",
    "batch_size = 32\n",
    "\n",
    "# Perform the actual training.\n",
    "if should_train:\n",
    "    history = model.fit(X, y, epochs=train_epochs, batch_size=batch_size, callbacks=[checkpoint])\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Prediction\n",
    "Time to make some music!  Don't forget to run the training section *without* actually retraining the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of the top predictions to choose from rather than taking the top choice only.\n",
    "# Setting to 1 always takes the best choice but may result in more repetition.\n",
    "num_top_preds = 5\n",
    "\n",
    "# Get a random starting point.\n",
    "start_idx = np.random.randint(0, len(data_X))\n",
    "start_pattern = data_X[start_idx]\n",
    "pattern = data_X[start_idx]\n",
    "print(f'Start: {start_idx}')\n",
    "\n",
    "output = []\n",
    "for idx in range(5 * SEQUENCE_LENGTH):\n",
    "#     print(f'Input: {[int_to_note[n] for n in pattern]}')\n",
    "    # Shape the input and make a prediction.\n",
    "    pred_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    pred_input = pred_input / float(len(flat_notes))\n",
    "    prediction = model.predict(pred_input)\n",
    "    \n",
    "    # Sample one of the best top choices.\n",
    "    top_predictions = np.argpartition(prediction[0], -num_top_preds)[-num_top_preds:]\n",
    "    predicted_index = top_predictions[np.random.randint(0, num_top_preds)]\n",
    "    \n",
    "#     print(f'\\t{[int_to_note[n] for n in top_predictions]}')\n",
    "    \n",
    "    # Convert and save the best choice out.\n",
    "    output.append(int_to_note[predicted_index])\n",
    "    \n",
    "    # Feed the data back through for the next prediction.\n",
    "    pattern.append(predicted_index) # (np.argmax(prediction[0]))\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "#end\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_roll_to_midi(output, SAMPLE_FREQ, './output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_roll_to_midi([int_to_note[n] for n in start_pattern], SAMPLE_FREQ, './pattern.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll = [int_to_note[n] for n in start_pattern] + output\n",
    "convert_roll_to_midi(roll, SAMPLE_FREQ, './combined.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
