{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Globals\n",
    "Let's first define some configuration variables that will be used throughout.  Always run this as different sections may use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLLS_FILE = './ragtime-generator.bin'\n",
    "MODEL_FILE = './ragtime-generator.hdf5'\n",
    "MIDI_PATH = './data/'\n",
    "\n",
    "MAX_DURATION = 12\n",
    "\n",
    "NOTE_SEP = '!'\n",
    "REST_KEY = '@'\n",
    "\n",
    "SEQUENCE_LENGTH = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Conversion\n",
    "Let's now preprocess all of the midi files into a representative format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "\n",
    "def convert_midi_to_roll(file):\n",
    "    midi = m21.converter.parse(file)\n",
    "    \n",
    "    note_filter = m21.stream.filters.ClassFilter('Note')\n",
    "    chord_filter = m21.stream.filters.ClassFilter('Chord')\n",
    "    rest_filter = m21.stream.filters.ClassFilter('Rest')\n",
    "\n",
    "    # Build a list of notes, chords, and rests and sort them by offset (time)\n",
    "    notes = []\n",
    "    notes.extend(list(midi.recurse().addFilter(note_filter)))\n",
    "    notes.extend(list(midi.recurse().addFilter(chord_filter)))\n",
    "    notes.extend(list(midi.recurse().addFilter(rest_filter)))\n",
    "    notes = sorted(notes, key=lambda x: x.offset)\n",
    "    \n",
    "    # Process the notes into a roll.\n",
    "    num_skipped = 0 # How many notes were skipped (for any reason)?\n",
    "    prev_offset = 0.0 # Previous element's offset. Used for dumping.\n",
    "    notes_to_dump = [] # Accumulated notes in a single offset.\n",
    "    durations_to_dump = [] # Durations matching notes_to_dump.\n",
    "    roll = []\n",
    "    for idx, el in enumerate(notes):\n",
    "        # Skip zero-length elements (midi bug).\n",
    "        if 'zero' == el.duration.type:\n",
    "            #print(f'Skipping zero duration: {el}')\n",
    "            num_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Skip lengthy durations.\n",
    "        if el.duration.quarterLength > MAX_DURATION:\n",
    "            #print(f'Skipping long duration {el.duration.quarterLength}: {el}')\n",
    "            num_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Dump notes when the next note's offset is different.\n",
    "        if el.offset != prev_offset:\n",
    "            if len(notes_to_dump): # Must have this to allow updating of the first element without dumping nothing.\n",
    "                roll.append(NOTE_SEP.join(str(n.pitch if isinstance(n, m21.note.Note) else n) + '$' + str(d) for n, d in zip(notes_to_dump, durations_to_dump)))\n",
    "                notes_to_dump = []\n",
    "                durations_to_dump = []\n",
    "            prev_offset = el.offset\n",
    "        \n",
    "        # Append notes.\n",
    "        if isinstance(el, m21.note.Note):\n",
    "            notes_to_dump.append(el)\n",
    "            durations_to_dump.append(el.duration.quarterLength)\n",
    "        \n",
    "        # Append notes from chords.\n",
    "        if isinstance(el, m21.chord.Chord):\n",
    "            notes_to_dump.extend(el.notes)\n",
    "            durations_to_dump.extend([el.duration.quarterLength for n in el.notes])\n",
    "        \n",
    "        # Append rests (instantly).\n",
    "        if isinstance(el, m21.note.Rest):\n",
    "            roll.append(f'{REST_KEY}${el.duration.quarterLength}')\n",
    "        \n",
    "    # Dump remaining notes.\n",
    "    if len(notes_to_dump):\n",
    "        roll.append(NOTE_SEP.join(str(n.pitch if isinstance(n, m21.note.Note) else n) + '$' + str(d) for n, d in zip(notes_to_dump, durations_to_dump)))\n",
    "        notes_to_dump = []\n",
    "        durations_to_dump = []\n",
    "    \n",
    "    return roll\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing rolls pickle.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# If the notes file already exists, just load it.\n",
    "if os.path.exists(ROLLS_FILE):\n",
    "    with open(ROLLS_FILE, 'rb') as file:\n",
    "        rolls = pickle.load(file)\n",
    "    print('Loaded existing rolls pickle.')\n",
    "else:\n",
    "    # Convert all midi files, saving their rolls into a list.\n",
    "    rolls = []\n",
    "    midi_files = ['./data/C_mapleaf.mid', './data/C_original.mid']#glob.glob(MIDI_PATH + '*.mid')\n",
    "    for midi_file in midi_files:\n",
    "        filename = os.path.basename(midi_file)\n",
    "        print(f'Processing `{filename}`...', end='')\n",
    "        roll = convert_midi_to_roll(midi_file)\n",
    "        rolls.append(roll)\n",
    "        print('done!')\n",
    "    \n",
    "    # Write out the rolls to a pickle.\n",
    "    with open(ROLLS_FILE, 'wb') as file:\n",
    "        pickle.dump(rolls, file)\n",
    "    print('Wrote rolls pickle to file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Training\n",
    "Now let's take all of the processed rolls and create the `X` and `y` data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings\n",
    "Generate some mappings to go between unique notes and integers.  The integers are used in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rolls flattened.\n",
    "flat_rolls = [item for sublist in rolls for item in sublist]\n",
    "\n",
    "# All unique notes across all flattened rolls.\n",
    "unique_notes = sorted(set(flat_rolls))\n",
    "\n",
    "# Build two dictionaries.  One maps notes (as strings) to ints, and the other backwards.\n",
    "# We use the first to convert the rolls into a sequence of integers, and the second to convert back to notes.\n",
    "note_to_int = dict((note, num) for num, note in enumerate(unique_notes))\n",
    "int_to_note = dict((num, note) for num, note in enumerate(unique_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X` and `y` data\n",
    "Building the training data using a sliding window.  Since the rolls are a nested list - one for each piece - I'm going to ensure that the sliding window does not go over a boundary (hence the nested lists).  Essentially, I'm creating `X` and `y` from sliding windows over different pieces joined together rather than treating the entire thing as one giant sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "# Apply a sliding window per piece but append the same data array.\n",
    "# This avoids a sliding window overlapping the boundaries between pieces.\n",
    "for roll in rolls:\n",
    "    for i in range(0, len(roll) - SEQUENCE_LENGTH):\n",
    "        # Snip a sequence of our piece as the X data of this window.\n",
    "        seq_in = roll[i:i + SEQUENCE_LENGTH]\n",
    "        data_X.append([note_to_int[n] for n in seq_in])\n",
    "        \n",
    "        # Take the next note as the y value to predict.\n",
    "        seq_out = roll[i + SEQUENCE_LENGTH]\n",
    "        data_y.append(note_to_int[seq_out])\n",
    "    #end\n",
    "#end\n",
    "\n",
    "# Create and shape the final X and y data for the network.\n",
    "X = np.reshape(data_X, (len(data_X), SEQUENCE_LENGTH, 1))\n",
    "X = X / float(len(flat_rolls))\n",
    "y = np_utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "Of course we now need to split our data into a training and testing set to better avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21226 train samples and 9097 test samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f'{len(X_train)} train samples and {len(X_test)} test samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "And now build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8, 128)            66560     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5827)              751683    \n",
      "=================================================================\n",
      "Total params: 949,827\n",
      "Trainable params: 949,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "import keras.backend as K\n",
    "\n",
    "# A fresh start when debugging\n",
    "K.clear_session()\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "#\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# TODO: Try a custom instance of ADAM with a lowered learning rate.\n",
    "# TODO: Investigate a custom loss function that takes into account what is a 'good' note."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights and/or train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing weights.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_FILE,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Load model weights if they already exist.\n",
    "if os.path.exists(MODEL_FILE):\n",
    "    model.load_weights(MODEL_FILE)\n",
    "    print('Loaded existing weights.')\n",
    "\n",
    "# Should training take place?\n",
    "should_train = False\n",
    "# How many epochs for?\n",
    "train_epochs = 50 # 100 total (50 before)\n",
    "# How many per batch?\n",
    "batch_size = 8*2\n",
    "\n",
    "if should_train:\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=train_epochs, batch_size=batch_size, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Prediction\n",
    "Now it's time to make some music!  Don't forget to load the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "\n",
    "def split_note_duration(pattern):\n",
    "    n, d = pattern.split('$')\n",
    "    if '/' in d:\n",
    "        a, b = d.split('/')\n",
    "        d = float(a) / float(b)\n",
    "    else:\n",
    "        d = float(d)\n",
    "    return n, d\n",
    "#end\n",
    "\n",
    "def convert_roll_to_midi(notes_array, filename):\n",
    "    offset = 0.0\n",
    "    output_notes = []\n",
    "    \n",
    "    for pattern in notes_array:\n",
    "        # handle chords (i.e. multiple notes split by NOTE_SEPARATOR)\n",
    "        if NOTE_SEP in pattern:\n",
    "            chord_notes = []\n",
    "            for chord_note in pattern.split(NOTE_SEP):\n",
    "                note_name, note_duration = split_note_duration(chord_note)\n",
    "                new_note = m21.note.Note(note_name)\n",
    "                new_note.offset = offset\n",
    "                new_note.storedInstrument = m21.instrument.Piano\n",
    "                new_note.duration = m21.duration.Duration(note_duration)\n",
    "                output_notes.append(new_note)\n",
    "#                 chord_notes.append(new_note)\n",
    "            #end\n",
    "            new_chord = m21.chord.Chord(chord_notes)\n",
    "            new_chord.offset = offset\n",
    "#             output_notes.append(new_chord)\n",
    "        #end\n",
    "        else:\n",
    "            note_name, note_duration = split_note_duration(pattern)\n",
    "            # handle rests\n",
    "            if REST_KEY == note_name:\n",
    "                new_rest = m21.note.Rest()\n",
    "                new_rest.offset = offset\n",
    "                new_rest.duration = m21.duration.Duration(note_duration)\n",
    "                output_notes.append(new_rest)\n",
    "            else:\n",
    "                new_note = m21.note.Note(note_name)\n",
    "                new_note.offset = offset\n",
    "                new_note.duration = m21.duration.Duration(note_duration)\n",
    "                output_notes.append(new_note)\n",
    "        #end\n",
    "        \n",
    "        offset += 0.25 # TODO: Solve this to not be fixed like this.\n",
    "    #end\n",
    "    \n",
    "    midi_stream = m21.stream.Stream(output_notes)\n",
    "    midi_stream.timeSignature = m21.meter.TimeSignature('2/4')\n",
    "    midi_stream.keySignature = m21.key.KeySignature(0)\n",
    "    midi_stream.write('midi', fp=filename)\n",
    "    return output_notes\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# How many of the best predictions to randomly select from instead of the best only.\n",
    "# Setting this to 1 takes the best prediction each time but is more prone to loops.\n",
    "num_top_preds = 3\n",
    "\n",
    "# If true, feeds the best choice back to the pattern even if another choice was chosen.\n",
    "feed_best_choice = False\n",
    "\n",
    "# Get a random starting point.\n",
    "start_idx = np.random.randint(0, len(data_X))\n",
    "pattern = data_X[start_idx]\n",
    "\n",
    "# Generate!\n",
    "output = []\n",
    "for idx in range(20 * SEQUENCE_LENGTH):\n",
    "    # Shape the input and make a prediction.\n",
    "    pred_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    pred_input = pred_input / float(len(flat_rolls))\n",
    "    predictions = model.predict(pred_input)\n",
    "    \n",
    "    # Sample one of the best top choices.\n",
    "    top_predictions = np.argpartition(predictions[0], -num_top_preds)[-num_top_preds:]\n",
    "    predicted_index = top_predictions[np.random.randint(0, num_top_preds)]\n",
    "    \n",
    "    # Convert and save the best choice.\n",
    "    output.append(int_to_note[predicted_index])\n",
    "    \n",
    "    # Feed data back into the prediction pattern.\n",
    "    pattern.append(np.argmax(predictions[0]) if feed_best_choice else predicted_index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write just the output.\n",
    "_ = convert_roll_to_midi(output, './output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train-new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
