{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Globals\n",
    "Let's first define some configuration variables that will be used throughout.  Always run this as different sections may use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLLS_FILE = './ragtime-generator.bin'\n",
    "MODEL_FILE = './ragtime-generator.hdf5'\n",
    "MIDI_PATH = './data/'\n",
    "\n",
    "MAX_DURATION = 12\n",
    "\n",
    "NOTE_SEP = '!'\n",
    "REST_KEY = '@'\n",
    "\n",
    "SEQUENCE_LENGTH = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Conversion\n",
    "Let's now preprocess all of the midi files into a representative format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "\n",
    "def convert_midi_to_roll(file):\n",
    "    midi = m21.converter.parse(file)\n",
    "    \n",
    "    note_filter = m21.stream.filters.ClassFilter('Note')\n",
    "    chord_filter = m21.stream.filters.ClassFilter('Chord')\n",
    "    rest_filter = m21.stream.filters.ClassFilter('Rest')\n",
    "\n",
    "    # Build a list of notes, chords, and rests and sort them by offset (time)\n",
    "    notes = []\n",
    "    notes.extend(list(midi.recurse().addFilter(note_filter)))\n",
    "    notes.extend(list(midi.recurse().addFilter(chord_filter)))\n",
    "    notes.extend(list(midi.recurse().addFilter(rest_filter)))\n",
    "    notes = sorted(notes, key=lambda x: x.offset)\n",
    "    \n",
    "    # Process the notes into a roll.\n",
    "    num_skipped = 0 # How many notes were skipped (for any reason)?\n",
    "    prev_offset = 0.0 # Previous element's offset. Used for dumping.\n",
    "    notes_to_dump = [] # Accumulated notes in a single offset.\n",
    "    durations_to_dump = [] # Durations matching notes_to_dump.\n",
    "    roll = []\n",
    "    for idx, el in enumerate(notes):\n",
    "        # Skip zero-length elements (midi bug).\n",
    "        if 'zero' == el.duration.type:\n",
    "            #print(f'Skipping zero duration: {el}')\n",
    "            num_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Skip lengthy durations.\n",
    "        if el.duration.quarterLength > MAX_DURATION:\n",
    "            #print(f'Skipping long duration {el.duration.quarterLength}: {el}')\n",
    "            num_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Dump notes when the next note's offset is different.\n",
    "        if el.offset != prev_offset:\n",
    "            if len(notes_to_dump): # Must have this to allow updating of the first element without dumping nothing.\n",
    "                roll.append(NOTE_SEP.join(str(n.pitch if isinstance(n, m21.note.Note) else n) + '$' + str(d) for n, d in zip(notes_to_dump, durations_to_dump)))\n",
    "                notes_to_dump = []\n",
    "                durations_to_dump = []\n",
    "            prev_offset = el.offset\n",
    "        \n",
    "        # Append notes.\n",
    "        if isinstance(el, m21.note.Note):\n",
    "            notes_to_dump.append(el)\n",
    "            durations_to_dump.append(el.duration.quarterLength)\n",
    "        \n",
    "        # Append notes from chords.\n",
    "        if isinstance(el, m21.chord.Chord):\n",
    "            notes_to_dump.extend(el.notes)\n",
    "            durations_to_dump.extend([el.duration.quarterLength for n in el.notes])\n",
    "        \n",
    "        # Append rests (instantly).\n",
    "        if isinstance(el, m21.note.Rest):\n",
    "            roll.append(f'{REST_KEY}${el.duration.quarterLength}')\n",
    "        \n",
    "    # Dump remaining notes.\n",
    "    if len(notes_to_dump):\n",
    "        roll.append(NOTE_SEP.join(str(n.pitch if isinstance(n, m21.note.Note) else n) + '$' + str(d) for n, d in zip(notes_to_dump, durations_to_dump)))\n",
    "        notes_to_dump = []\n",
    "        durations_to_dump = []\n",
    "    \n",
    "    return roll\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing `C_mapleaf.mid`...done!\n",
      "Processing `C_original.mid`...done!\n",
      "Wrote rolls pickle to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# If the notes file already exists, just load it.\n",
    "if os.path.exists(ROLLS_FILE):\n",
    "    with open(ROLLS_FILE, 'rb') as file:\n",
    "        rolls = pickle.load(file)\n",
    "else:\n",
    "    # Convert all midi files, saving their rolls into a list.\n",
    "    rolls = []\n",
    "    midi_files = ['./data/C_mapleaf.mid', './data/C_original.mid']#glob.glob(MIDI_PATH + '*.mid')\n",
    "    for midi_file in midi_files:\n",
    "        filename = os.path.basename(midi_file)\n",
    "        print(f'Processing `{filename}`...', end='')\n",
    "        roll = convert_midi_to_roll(midi_file)\n",
    "        rolls.append(roll)\n",
    "        print('done!')\n",
    "    \n",
    "    # Write out the rolls to a pickle.\n",
    "    with open(ROLLS_FILE, 'wb') as file:\n",
    "        pickle.dump(rolls, file)\n",
    "    print('Wrote rolls pickle to file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Training\n",
    "Now let's take all of the processed rolls and create the `X` and `y` data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings\n",
    "Generate some mappings to go between unique notes and integers.  The integers are used in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rolls flattened.\n",
    "flat_rolls = [item for sublist in rolls for item in sublist]\n",
    "\n",
    "# All unique notes across all flattened rolls.\n",
    "unique_notes = sorted(set(flat_rolls))\n",
    "\n",
    "# Build two dictionaries.  One maps notes (as strings) to ints, and the other backwards.\n",
    "# We use the first to convert the rolls into a sequence of integers, and the second to convert back to notes.\n",
    "note_to_int = dict((note, num) for num, note in enumerate(unique_notes))\n",
    "int_to_note = dict((num, note) for num, note in enumerate(unique_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X` and `y` data\n",
    "Building the training data using a sliding window.  Since the rolls are a nested list - one for each piece - I'm going to ensure that the sliding window does not go over a boundary (hence the nested lists).  Essentially, I'm creating `X` and `y` from sliding windows over different pieces joined together rather than treating the entire thing as one giant sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "# Apply a sliding window per piece but append the same data array.\n",
    "# This avoids a sliding window overlapping the boundaries between pieces.\n",
    "for roll in rolls:\n",
    "    for i in range(0, len(roll) - SEQUENCE_LENGTH):\n",
    "        # Snip a sequence of our piece as the X data of this window.\n",
    "        seq_in = roll[i:i + SEQUENCE_LENGTH]\n",
    "        data_X.append([note_to_int[n] for n in seq_in])\n",
    "        \n",
    "        # Take the next note as the y value to predict.\n",
    "        seq_out = roll[i + SEQUENCE_LENGTH]\n",
    "        data_y.append(note_to_int[seq_out])\n",
    "    #end\n",
    "#end\n",
    "\n",
    "# Create and shape the final X and y data for the network.\n",
    "X = np.reshape(data_X, (len(data_X), SEQUENCE_LENGTH, 1))\n",
    "X = X / float(len(flat_rolls))\n",
    "y = np_utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "And now build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8, 128)            66560     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 517)               66693     \n",
      "=================================================================\n",
      "Total params: 264,837\n",
      "Trainable params: 264,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "import keras.backend as K\n",
    "\n",
    "# A fresh start when debugging\n",
    "K.clear_session()\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "#\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# TODO: Use a custom instance of ADAM with a lowered learning rate.\n",
    "# TODO: Investigate a custom loss function that takes into account what is a 'good' note."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights and/or train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing weights.\n",
      "Epoch 1/150\n",
      "2425/2425 [==============================] - 2s 621us/step - loss: 5.1578 - accuracy: 0.1080\n",
      "Epoch 2/150\n",
      "2425/2425 [==============================] - 2s 712us/step - loss: 5.1099 - accuracy: 0.1064\n",
      "Epoch 3/150\n",
      "2425/2425 [==============================] - 2s 846us/step - loss: 5.1225 - accuracy: 0.1068\n",
      "Epoch 4/150\n",
      "2425/2425 [==============================] - 1s 597us/step - loss: 5.1111 - accuracy: 0.1122\n",
      "Epoch 5/150\n",
      "2425/2425 [==============================] - 1s 609us/step - loss: 5.0843 - accuracy: 0.1130\n",
      "Epoch 6/150\n",
      "2425/2425 [==============================] - 2s 626us/step - loss: 5.0775 - accuracy: 0.1118\n",
      "Epoch 7/150\n",
      "2425/2425 [==============================] - 1s 605us/step - loss: 5.0506 - accuracy: 0.1179\n",
      "Epoch 8/150\n",
      "2425/2425 [==============================] - 1s 609us/step - loss: 5.0470 - accuracy: 0.1163\n",
      "Epoch 9/150\n",
      "2425/2425 [==============================] - 1s 609us/step - loss: 4.9912 - accuracy: 0.1241\n",
      "Epoch 10/150\n",
      "2425/2425 [==============================] - 2s 627us/step - loss: 4.9799 - accuracy: 0.1184\n",
      "Epoch 11/150\n",
      "2425/2425 [==============================] - 2s 620us/step - loss: 4.9592 - accuracy: 0.1229\n",
      "Epoch 12/150\n",
      "2425/2425 [==============================] - 1s 611us/step - loss: 4.9042 - accuracy: 0.1208\n",
      "Epoch 13/150\n",
      "2425/2425 [==============================] - 1s 613us/step - loss: 4.9082 - accuracy: 0.1282\n",
      "Epoch 14/150\n",
      "2425/2425 [==============================] - 1s 614us/step - loss: 4.8448 - accuracy: 0.1254\n",
      "Epoch 15/150\n",
      "2425/2425 [==============================] - 1s 611us/step - loss: 4.8172 - accuracy: 0.1328\n",
      "Epoch 16/150\n",
      "2425/2425 [==============================] - 2s 628us/step - loss: 4.8226 - accuracy: 0.1353\n",
      "Epoch 17/150\n",
      "2425/2425 [==============================] - 1s 613us/step - loss: 4.7470 - accuracy: 0.1357\n",
      "Epoch 18/150\n",
      "2425/2425 [==============================] - 2s 622us/step - loss: 4.7618 - accuracy: 0.1381\n",
      "Epoch 19/150\n",
      "2425/2425 [==============================] - 2s 623us/step - loss: 4.7343 - accuracy: 0.1464\n",
      "Epoch 20/150\n",
      "2425/2425 [==============================] - 2s 712us/step - loss: 4.6943 - accuracy: 0.1423\n",
      "Epoch 21/150\n",
      "2425/2425 [==============================] - 2s 662us/step - loss: 4.6494 - accuracy: 0.1518\n",
      "Epoch 22/150\n",
      "2425/2425 [==============================] - 2s 651us/step - loss: 4.6060 - accuracy: 0.1584\n",
      "Epoch 23/150\n",
      "2425/2425 [==============================] - 2s 642us/step - loss: 4.5752 - accuracy: 0.1633\n",
      "Epoch 24/150\n",
      "2425/2425 [==============================] - 2s 637us/step - loss: 4.5282 - accuracy: 0.1666\n",
      "Epoch 25/150\n",
      "2425/2425 [==============================] - 2s 636us/step - loss: 4.4779 - accuracy: 0.1720\n",
      "Epoch 26/150\n",
      "2425/2425 [==============================] - 2s 667us/step - loss: 4.4569 - accuracy: 0.1682\n",
      "Epoch 27/150\n",
      "2425/2425 [==============================] - 2s 642us/step - loss: 4.4478 - accuracy: 0.1781\n",
      "Epoch 28/150\n",
      "2425/2425 [==============================] - 2s 644us/step - loss: 4.3967 - accuracy: 0.1748\n",
      "Epoch 29/150\n",
      "2425/2425 [==============================] - 2s 639us/step - loss: 4.3545 - accuracy: 0.1901\n",
      "Epoch 30/150\n",
      "2425/2425 [==============================] - 2s 638us/step - loss: 4.3512 - accuracy: 0.1905\n",
      "Epoch 31/150\n",
      "2425/2425 [==============================] - 2s 636us/step - loss: 4.3071 - accuracy: 0.1959\n",
      "Epoch 32/150\n",
      "2425/2425 [==============================] - 2s 636us/step - loss: 4.2778 - accuracy: 0.1901\n",
      "Epoch 33/150\n",
      "2425/2425 [==============================] - 2s 647us/step - loss: 4.2370 - accuracy: 0.2091\n",
      "Epoch 34/150\n",
      "2425/2425 [==============================] - 2s 637us/step - loss: 4.2137 - accuracy: 0.1984\n",
      "Epoch 35/150\n",
      "2425/2425 [==============================] - 2s 638us/step - loss: 4.2116 - accuracy: 0.2111\n",
      "Epoch 36/150\n",
      "2425/2425 [==============================] - 1s 605us/step - loss: 4.1512 - accuracy: 0.2120\n",
      "Epoch 37/150\n",
      "2425/2425 [==============================] - 2s 638us/step - loss: 4.1509 - accuracy: 0.2202\n",
      "Epoch 38/150\n",
      "2425/2425 [==============================] - 2s 643us/step - loss: 4.1537 - accuracy: 0.2190\n",
      "Epoch 39/150\n",
      "2425/2425 [==============================] - 2s 638us/step - loss: 4.1243 - accuracy: 0.2305\n",
      "Epoch 40/150\n",
      "2425/2425 [==============================] - 2s 627us/step - loss: 4.1009 - accuracy: 0.2165\n",
      "Epoch 41/150\n",
      "2425/2425 [==============================] - 2s 627us/step - loss: 4.0237 - accuracy: 0.2503\n",
      "Epoch 42/150\n",
      "2425/2425 [==============================] - 2s 636us/step - loss: 3.9905 - accuracy: 0.2528\n",
      "Epoch 43/150\n",
      "2425/2425 [==============================] - 1s 616us/step - loss: 4.0373 - accuracy: 0.2503\n",
      "Epoch 44/150\n",
      "2425/2425 [==============================] - 1s 608us/step - loss: 4.0255 - accuracy: 0.2528\n",
      "Epoch 45/150\n",
      "2425/2425 [==============================] - 2s 637us/step - loss: 3.9967 - accuracy: 0.2528\n",
      "Epoch 46/150\n",
      "2425/2425 [==============================] - 2s 620us/step - loss: 3.9878 - accuracy: 0.2668\n",
      "Epoch 47/150\n",
      "2425/2425 [==============================] - 2s 630us/step - loss: 3.9876 - accuracy: 0.2532\n",
      "Epoch 48/150\n",
      "2425/2425 [==============================] - 2s 621us/step - loss: 3.9571 - accuracy: 0.2685\n",
      "Epoch 49/150\n",
      "2425/2425 [==============================] - 1s 615us/step - loss: 3.9592 - accuracy: 0.2627\n",
      "Epoch 50/150\n",
      "2425/2425 [==============================] - 2s 622us/step - loss: 3.9551 - accuracy: 0.2693\n",
      "Epoch 51/150\n",
      "2425/2425 [==============================] - 2s 622us/step - loss: 3.9332 - accuracy: 0.2709\n",
      "Epoch 52/150\n",
      "2425/2425 [==============================] - 1s 616us/step - loss: 3.9075 - accuracy: 0.2788\n",
      "Epoch 53/150\n",
      "2425/2425 [==============================] - 2s 629us/step - loss: 3.9164 - accuracy: 0.2845\n",
      "Epoch 54/150\n",
      "2425/2425 [==============================] - 1s 603us/step - loss: 3.9112 - accuracy: 0.2718\n",
      "Epoch 55/150\n",
      "2425/2425 [==============================] - 1s 601us/step - loss: 3.9332 - accuracy: 0.2854\n",
      "Epoch 56/150\n",
      "2425/2425 [==============================] - 1s 603us/step - loss: 3.8980 - accuracy: 0.2882\n",
      "Epoch 57/150\n",
      "2425/2425 [==============================] - 1s 600us/step - loss: 3.8996 - accuracy: 0.2841\n",
      "Epoch 58/150\n",
      "2425/2425 [==============================] - 1s 602us/step - loss: 3.8880 - accuracy: 0.2953\n",
      "Epoch 59/150\n",
      "2425/2425 [==============================] - 2s 680us/step - loss: 3.8742 - accuracy: 0.2965\n",
      "Epoch 60/150\n",
      "2425/2425 [==============================] - 2s 639us/step - loss: 3.8667 - accuracy: 0.2986\n",
      "Epoch 61/150\n",
      "2425/2425 [==============================] - 2s 626us/step - loss: 3.8726 - accuracy: 0.3006\n",
      "Epoch 62/150\n",
      "2425/2425 [==============================] - 1s 607us/step - loss: 3.8582 - accuracy: 0.3072\n",
      "Epoch 63/150\n",
      "2425/2425 [==============================] - 1s 610us/step - loss: 3.8714 - accuracy: 0.3043\n",
      "Epoch 64/150\n",
      "2425/2425 [==============================] - 1s 607us/step - loss: 3.8734 - accuracy: 0.3047\n",
      "Epoch 65/150\n",
      "2425/2425 [==============================] - 2s 637us/step - loss: 3.8702 - accuracy: 0.3023\n",
      "Epoch 66/150\n",
      "2425/2425 [==============================] - 2s 786us/step - loss: 3.8382 - accuracy: 0.3159\n",
      "Epoch 67/150\n",
      "2425/2425 [==============================] - 2s 698us/step - loss: 3.8696 - accuracy: 0.3142\n",
      "Epoch 68/150\n",
      "2425/2425 [==============================] - 2s 739us/step - loss: 3.8512 - accuracy: 0.3175\n",
      "Epoch 69/150\n",
      "2425/2425 [==============================] - 2s 640us/step - loss: 3.8285 - accuracy: 0.3254\n",
      "Epoch 70/150\n",
      "2425/2425 [==============================] - 1s 601us/step - loss: 3.8375 - accuracy: 0.3208\n",
      "Epoch 71/150\n",
      "2425/2425 [==============================] - 1s 605us/step - loss: 3.8213 - accuracy: 0.3348\n",
      "Epoch 72/150\n",
      "2425/2425 [==============================] - 1s 601us/step - loss: 3.8431 - accuracy: 0.3340\n",
      "Epoch 73/150\n",
      "2425/2425 [==============================] - 1s 602us/step - loss: 3.8071 - accuracy: 0.3282\n",
      "Epoch 74/150\n",
      "2425/2425 [==============================] - 1s 610us/step - loss: 3.8226 - accuracy: 0.3340\n",
      "Epoch 75/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.8208 - accuracy: 0.3410\n",
      "Epoch 76/150\n",
      "2425/2425 [==============================] - 1s 597us/step - loss: 3.7953 - accuracy: 0.3464\n",
      "Epoch 77/150\n",
      "2425/2425 [==============================] - 1s 603us/step - loss: 3.8226 - accuracy: 0.3472\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2425/2425 [==============================] - 1s 588us/step - loss: 3.8175 - accuracy: 0.3439\n",
      "Epoch 79/150\n",
      "2425/2425 [==============================] - 1s 590us/step - loss: 3.8167 - accuracy: 0.3497\n",
      "Epoch 80/150\n",
      "2425/2425 [==============================] - 1s 592us/step - loss: 3.8285 - accuracy: 0.3497\n",
      "Epoch 81/150\n",
      "2425/2425 [==============================] - 1s 592us/step - loss: 3.8264 - accuracy: 0.3493\n",
      "Epoch 82/150\n",
      "2425/2425 [==============================] - 1s 593us/step - loss: 3.8042 - accuracy: 0.3468\n",
      "Epoch 83/150\n",
      "2425/2425 [==============================] - 1s 594us/step - loss: 3.8075 - accuracy: 0.3567\n",
      "Epoch 84/150\n",
      "2425/2425 [==============================] - 1s 591us/step - loss: 3.8133 - accuracy: 0.3579\n",
      "Epoch 85/150\n",
      "2425/2425 [==============================] - 1s 603us/step - loss: 3.8221 - accuracy: 0.3464\n",
      "Epoch 86/150\n",
      "2425/2425 [==============================] - 1s 594us/step - loss: 3.8332 - accuracy: 0.3608\n",
      "Epoch 87/150\n",
      "2425/2425 [==============================] - 1s 595us/step - loss: 3.8062 - accuracy: 0.3637\n",
      "Epoch 88/150\n",
      "2425/2425 [==============================] - 1s 605us/step - loss: 3.8232 - accuracy: 0.3600\n",
      "Epoch 89/150\n",
      "2425/2425 [==============================] - 1s 610us/step - loss: 3.8149 - accuracy: 0.3674\n",
      "Epoch 90/150\n",
      "2425/2425 [==============================] - 1s 613us/step - loss: 3.8076 - accuracy: 0.3629\n",
      "Epoch 91/150\n",
      "2425/2425 [==============================] - 1s 615us/step - loss: 3.8085 - accuracy: 0.3629\n",
      "Epoch 92/150\n",
      "2425/2425 [==============================] - 1s 614us/step - loss: 3.7964 - accuracy: 0.3658\n",
      "Epoch 93/150\n",
      "2425/2425 [==============================] - 1s 598us/step - loss: 3.7961 - accuracy: 0.3707\n",
      "Epoch 94/150\n",
      "2425/2425 [==============================] - 1s 607us/step - loss: 3.8204 - accuracy: 0.3641\n",
      "Epoch 95/150\n",
      "2425/2425 [==============================] - 1s 601us/step - loss: 3.7987 - accuracy: 0.3802\n",
      "Epoch 96/150\n",
      "2425/2425 [==============================] - 2s 620us/step - loss: 3.7964 - accuracy: 0.3847\n",
      "Epoch 97/150\n",
      "2425/2425 [==============================] - 2s 621us/step - loss: 3.7812 - accuracy: 0.3847\n",
      "Epoch 98/150\n",
      "2425/2425 [==============================] - 1s 605us/step - loss: 3.7864 - accuracy: 0.3802\n",
      "Epoch 99/150\n",
      "2425/2425 [==============================] - 2s 631us/step - loss: 3.7536 - accuracy: 0.3847\n",
      "Epoch 100/150\n",
      "2425/2425 [==============================] - 2s 622us/step - loss: 3.7640 - accuracy: 0.3868\n",
      "Epoch 101/150\n",
      "2425/2425 [==============================] - 1s 609us/step - loss: 3.7620 - accuracy: 0.3823\n",
      "Epoch 102/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.7505 - accuracy: 0.3868\n",
      "Epoch 103/150\n",
      "2425/2425 [==============================] - 1s 615us/step - loss: 3.7467 - accuracy: 0.3868\n",
      "Epoch 104/150\n",
      "2425/2425 [==============================] - 1s 616us/step - loss: 3.7285 - accuracy: 0.3922\n",
      "Epoch 105/150\n",
      "2425/2425 [==============================] - 1s 604us/step - loss: 3.7207 - accuracy: 0.3975\n",
      "Epoch 106/150\n",
      "2425/2425 [==============================] - 1s 616us/step - loss: 3.7155 - accuracy: 0.4016\n",
      "Epoch 107/150\n",
      "2425/2425 [==============================] - 1s 600us/step - loss: 3.7043 - accuracy: 0.3979\n",
      "Epoch 108/150\n",
      "2425/2425 [==============================] - 1s 597us/step - loss: 3.6894 - accuracy: 0.4033\n",
      "Epoch 109/150\n",
      "2425/2425 [==============================] - 1s 600us/step - loss: 3.6962 - accuracy: 0.4016\n",
      "Epoch 110/150\n",
      "2425/2425 [==============================] - 1s 600us/step - loss: 3.6774 - accuracy: 0.4037\n",
      "Epoch 111/150\n",
      "2425/2425 [==============================] - 1s 595us/step - loss: 3.6670 - accuracy: 0.4095\n",
      "Epoch 112/150\n",
      "2425/2425 [==============================] - 1s 600us/step - loss: 3.6557 - accuracy: 0.4070\n",
      "Epoch 113/150\n",
      "2425/2425 [==============================] - 1s 597us/step - loss: 3.6620 - accuracy: 0.4041\n",
      "Epoch 114/150\n",
      "2425/2425 [==============================] - 1s 603us/step - loss: 3.6515 - accuracy: 0.4095\n",
      "Epoch 115/150\n",
      "2425/2425 [==============================] - 2s 633us/step - loss: 3.6314 - accuracy: 0.4041\n",
      "Epoch 116/150\n",
      "2425/2425 [==============================] - 2s 786us/step - loss: 3.6389 - accuracy: 0.4120\n",
      "Epoch 117/150\n",
      "2425/2425 [==============================] - 2s 807us/step - loss: 3.6171 - accuracy: 0.4144\n",
      "Epoch 118/150\n",
      "2425/2425 [==============================] - 2s 703us/step - loss: 3.5951 - accuracy: 0.4210\n",
      "Epoch 119/150\n",
      "2425/2425 [==============================] - 2s 731us/step - loss: 3.6013 - accuracy: 0.4161\n",
      "Epoch 120/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.5955 - accuracy: 0.4165\n",
      "Epoch 121/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.5794 - accuracy: 0.4272\n",
      "Epoch 122/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.5588 - accuracy: 0.4293\n",
      "Epoch 123/150\n",
      "2425/2425 [==============================] - 1s 598us/step - loss: 3.5612 - accuracy: 0.4247\n",
      "Epoch 124/150\n",
      "2425/2425 [==============================] - 1s 599us/step - loss: 3.5665 - accuracy: 0.4280\n",
      "Epoch 125/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.5431 - accuracy: 0.4247\n",
      "Epoch 126/150\n",
      "2425/2425 [==============================] - 1s 601us/step - loss: 3.5439 - accuracy: 0.4268\n",
      "Epoch 127/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.5353 - accuracy: 0.4375\n",
      "Epoch 128/150\n",
      "2425/2425 [==============================] - 1s 595us/step - loss: 3.5330 - accuracy: 0.4276\n",
      "Epoch 129/150\n",
      "2425/2425 [==============================] - 1s 582us/step - loss: 3.5120 - accuracy: 0.4346\n",
      "Epoch 130/150\n",
      "2425/2425 [==============================] - 1s 596us/step - loss: 3.4968 - accuracy: 0.4359\n",
      "Epoch 131/150\n",
      "2425/2425 [==============================] - 1s 597us/step - loss: 3.5205 - accuracy: 0.4322\n",
      "Epoch 132/150\n",
      "2425/2425 [==============================] - 1s 600us/step - loss: 3.5062 - accuracy: 0.4363\n",
      "Epoch 133/150\n",
      "2425/2425 [==============================] - 1s 598us/step - loss: 3.4956 - accuracy: 0.4392\n",
      "Epoch 134/150\n",
      "2425/2425 [==============================] - 1s 606us/step - loss: 3.4942 - accuracy: 0.4363\n",
      "Epoch 135/150\n",
      "2425/2425 [==============================] - 1s 617us/step - loss: 3.4840 - accuracy: 0.4445\n",
      "Epoch 136/150\n",
      "2425/2425 [==============================] - 1s 614us/step - loss: 3.4588 - accuracy: 0.4462\n",
      "Epoch 137/150\n",
      "2425/2425 [==============================] - 1s 597us/step - loss: 3.4650 - accuracy: 0.4458\n",
      "Epoch 138/150\n",
      "2425/2425 [==============================] - 1s 599us/step - loss: 3.4670 - accuracy: 0.4445\n",
      "Epoch 139/150\n",
      "2425/2425 [==============================] - 2s 641us/step - loss: 3.4457 - accuracy: 0.4454\n",
      "Epoch 140/150\n",
      "2425/2425 [==============================] - 1s 618us/step - loss: 3.4403 - accuracy: 0.4511\n",
      "Epoch 141/150\n",
      "2425/2425 [==============================] - 1s 607us/step - loss: 3.4436 - accuracy: 0.4532\n",
      "Epoch 142/150\n",
      "2425/2425 [==============================] - 1s 597us/step - loss: 3.4310 - accuracy: 0.4586\n",
      "Epoch 143/150\n",
      "2425/2425 [==============================] - 1s 601us/step - loss: 3.4287 - accuracy: 0.4482\n",
      "Epoch 144/150\n",
      "2425/2425 [==============================] - 1s 602us/step - loss: 3.4218 - accuracy: 0.4515\n",
      "Epoch 145/150\n",
      "2425/2425 [==============================] - 1s 617us/step - loss: 3.4311 - accuracy: 0.4553\n",
      "Epoch 146/150\n",
      "2425/2425 [==============================] - 2s 744us/step - loss: 3.4152 - accuracy: 0.4503\n",
      "Epoch 147/150\n",
      "2425/2425 [==============================] - 2s 780us/step - loss: 3.4122 - accuracy: 0.4507\n",
      "Epoch 148/150\n",
      "2425/2425 [==============================] - 2s 658us/step - loss: 3.4053 - accuracy: 0.4577\n",
      "Epoch 149/150\n",
      "2425/2425 [==============================] - 2s 624us/step - loss: 3.3997 - accuracy: 0.4557\n",
      "Epoch 150/150\n",
      "2425/2425 [==============================] - 2s 621us/step - loss: 3.3898 - accuracy: 0.4557\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_FILE,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Load model weights if they already exist.\n",
    "if os.path.exists(MODEL_FILE):\n",
    "    model.load_weights(MODEL_FILE)\n",
    "    print('Loaded existing weights.')\n",
    "\n",
    "# Should training take place?\n",
    "should_train = True\n",
    "# How many epochs for?\n",
    "train_epochs = 150\n",
    "# How many per batch?\n",
    "batch_size = 8*2\n",
    "\n",
    "if should_train:\n",
    "    history = model.fit(X, y, epochs=train_epochs, batch_size=batch_size, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Prediction\n",
    "Now it's time to make some music!  Don't forget to load the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "\n",
    "def split_note_duration(pattern):\n",
    "    n, d = pattern.split('$')\n",
    "    if '/' in d:\n",
    "        a, b = d.split('/')\n",
    "        d = float(a) / float(b)\n",
    "    else:\n",
    "        d = float(d)\n",
    "    return n, d\n",
    "#end\n",
    "\n",
    "def convert_roll_to_midi(notes_array, filename):\n",
    "    offset = 0.0\n",
    "    output_notes = []\n",
    "    \n",
    "    for pattern in notes_array:\n",
    "        # handle chords (i.e. multiple notes split by NOTE_SEPARATOR)\n",
    "        if NOTE_SEP in pattern:\n",
    "            chord_notes = []\n",
    "            for chord_note in pattern.split(NOTE_SEP):\n",
    "                note_name, note_duration = split_note_duration(chord_note)\n",
    "                new_note = m21.note.Note(note_name)\n",
    "                new_note.offset = offset\n",
    "                new_note.storedInstrument = m21.instrument.Piano\n",
    "                new_note.duration = m21.duration.Duration(note_duration)\n",
    "                output_notes.append(new_note)\n",
    "#                 chord_notes.append(new_note)\n",
    "            #end\n",
    "            new_chord = m21.chord.Chord(chord_notes)\n",
    "            new_chord.offset = offset\n",
    "#             output_notes.append(new_chord)\n",
    "        #end\n",
    "        else:\n",
    "            note_name, note_duration = split_note_duration(pattern)\n",
    "            # handle rests\n",
    "            if REST_KEY == note_name:\n",
    "                new_rest = m21.note.Rest()\n",
    "                new_rest.offset = offset\n",
    "                new_rest.duration = m21.duration.Duration(note_duration)\n",
    "                output_notes.append(new_rest)\n",
    "            else:\n",
    "                new_note = m21.note.Note(note_name)\n",
    "                new_note.offset = offset\n",
    "                new_note.duration = m21.duration.Duration(note_duration)\n",
    "                output_notes.append(new_note)\n",
    "        #end\n",
    "        \n",
    "        offset += 0.25 # TODO: Solve this to not be fixed like this.\n",
    "    #end\n",
    "    \n",
    "    midi_stream = m21.stream.Stream(output_notes)\n",
    "    midi_stream.timeSignature = m21.meter.TimeSignature('2/4')\n",
    "    midi_stream.keySignature = m21.key.KeySignature(0)\n",
    "    midi_stream.write('midi', fp=filename)\n",
    "    return output_notes\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# How many of the best predictions to randomly select from instead of the best only.\n",
    "# Setting this to 1 takes the best prediction each time but is more prone to loops.\n",
    "num_top_preds = 3\n",
    "\n",
    "# If true, feeds the best choice back to the pattern even if another choice was chosen.\n",
    "feed_best_choice = False\n",
    "\n",
    "# Get a random starting point.\n",
    "start_idx = np.random.randint(0, len(data_X))\n",
    "pattern = data_X[start_idx]\n",
    "\n",
    "# Generate!\n",
    "output = []\n",
    "for idx in range(20 * SEQUENCE_LENGTH):\n",
    "    # Shape the input and make a prediction.\n",
    "    pred_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    pred_input = pred_input / float(len(flat_rolls))\n",
    "    predictions = model.predict(pred_input)\n",
    "    \n",
    "    # Sample one of the best top choices.\n",
    "    top_predictions = np.argpartition(predictions[0], -num_top_preds)[-num_top_preds:]\n",
    "    predicted_index = top_predictions[np.random.randint(0, num_top_preds)]\n",
    "    \n",
    "    # Convert and save the best choice.\n",
    "    output.append(int_to_note[predicted_index])\n",
    "    \n",
    "    # Feed data back into the prediction pattern.\n",
    "    pattern.append(np.argmax(predictions[0]) if feed_best_choice else predicted_index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write just the output.\n",
    "_ = convert_roll_to_midi(output, './output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train-new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
