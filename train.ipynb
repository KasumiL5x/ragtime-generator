{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from music21 import instrument, note, stream, chord, converter, duration\n",
    "\n",
    "MAX_DURATION = 8.0 # 2 bars\n",
    "NOTE_SEPARATOR = '!'\n",
    "REST_VALUE = '@'\n",
    "\n",
    "def get_notes(files):\n",
    "    notes = []\n",
    "\n",
    "    for f in files:\n",
    "        print(f'Parsing \\\"{f}\\\"...')\n",
    "        midi = converter.parse(f)\n",
    "        \n",
    "        # get raw midi notes from the first instrument\n",
    "        notes_to_parse = None\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        #end\n",
    "\n",
    "        num_skipped = 0 # how many notes did we skip for this piece?\n",
    "        prev_offset = 0.0 # what was the offset of the last set of elements?\n",
    "        notes_to_dump = [] # accumulation of notes with the same offset\n",
    "        durations_to_dump = [] # list of durations matching notes_to_dump\n",
    "        for idx, el in enumerate(notes_to_parse):\n",
    "            if not isinstance(el, note.Note) and not isinstance(el, chord.Chord) and not isinstance(el, note.Rest):\n",
    "                # print(f'Skipping element (not a note/chord): {el}')\n",
    "                num_skipped += 1\n",
    "                continue\n",
    "            #end\n",
    "\n",
    "            # skip zero length notes (alternatively we could give them a minimum duration here instead)\n",
    "            if 'zero' == el.duration.type:\n",
    "                # print(f'Skipping note {idx} with zero duration: {el}')\n",
    "                num_skipped += 1\n",
    "                continue\n",
    "            #end\n",
    "            \n",
    "            \n",
    "            # skip lengthy durations\n",
    "            if el.duration.quarterLength > MAX_DURATION:\n",
    "                #print(f'Skipped long duration ({el.duration.quarterLength}).')\n",
    "                num_skipped += 1\n",
    "                continue\n",
    "            #end\n",
    "\n",
    "            # dump notes when required and reset trackers\n",
    "            if el.offset != prev_offset:\n",
    "                if len(notes_to_dump): # only dump when there's something to dump - cannot put this in the main IF as we need to run it for the first element to update the offset\n",
    "                    notes.append(NOTE_SEPARATOR.join(str(n.pitch if isinstance(n, note.Note) else n) + '$' + str(d) for n, d in zip(notes_to_dump, durations_to_dump)))\n",
    "                    notes_to_dump = []\n",
    "                    durations_to_dump = []\n",
    "                #end\n",
    "                prev_offset = el.offset\n",
    "            #end\n",
    "\n",
    "            # append the notes to dump list\n",
    "            if isinstance(el, note.Note):\n",
    "                notes_to_dump.append(el)\n",
    "                durations_to_dump.append(el.duration.quarterLength)\n",
    "            elif isinstance(el, chord.Chord):\n",
    "                notes_to_dump.extend(el.notes)\n",
    "                durations_to_dump.extend([el.duration.quarterLength for n in el.notes])\n",
    "            elif isinstance(el, note.Rest):\n",
    "                # dump immediately if no pending notes exist.\n",
    "                # this is to avoid having rests accompanying notes.\n",
    "                # if you want this behavior, use `notes_to_dump.append(REST_VALUE)` and nothing more.\n",
    "                if not len(notes_to_dump):\n",
    "                    notes.append(f'{REST_VALUE}${el.duration.quarterLength}')\n",
    "        #end\n",
    "\n",
    "        if len(notes_to_dump) != 0:\n",
    "            notes.append(NOTE_SEPARATOR.join(str(n.pitch if isinstance(n, note.Note) else n) + '$' + str(d) for n, d in zip(notes_to_dump, durations_to_dump)))\n",
    "            notes_to_dump = []\n",
    "            durations_to_dump = []\n",
    "        #end\n",
    "\n",
    "        print(f'Finished parsing. Skipped {num_skipped} notes.')\n",
    "    #end\n",
    "\n",
    "    return notes\n",
    "#end\n",
    "\n",
    "# TESTING:\n",
    "# notes_array_to_midi(get_notes(['./data/C_mapleaf.mid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('./raggen-notes.bin'):\n",
    "    notes = pickle.load(open('./raggen-notes.bin', 'rb'))\n",
    "else:\n",
    "    pieces = glob.glob('./data/*.mid')\n",
    "    notes = get_notes(pieces)\n",
    "    with open('./raggen-notes.bin', 'wb') as notes_file:\n",
    "        pickle.dump(notes, notes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55931,
     "status": "ok",
     "timestamp": 1571556324211,
     "user": {
      "displayName": "Daniel Green",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCFRtqS5I7HVNdoY-OISy3BzinululKE6uTawrZ4g=s64",
      "userId": "17744463245578873670"
     },
     "user_tz": -60
    },
    "id": "1abojxpSysFm",
    "outputId": "cbe7baf0-58fc-41ce-98dd-2f1463f3a1e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique notes: 5806\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "TIMESTEP = 0.5 # 16th notes\n",
    "SEQ_LEN = int(4 / TIMESTEP) # 8 per bar\n",
    "\n",
    "num_unique_notes = len(set(notes))\n",
    "print(f'Number of unique notes: {num_unique_notes}')\n",
    "\n",
    "# all unique pitches (including rests)\n",
    "pitch_names = sorted(set(i for i in notes))\n",
    "# map pitches to integers\n",
    "note_to_int = dict((note, num) for num, note in enumerate(pitch_names))\n",
    "\n",
    "data_X = []\n",
    "data_y = []\n",
    "for i in range(0, len(notes) - SEQ_LEN, 1):\n",
    "    seq_in = notes[i:i + SEQ_LEN]\n",
    "    data_X.append([note_to_int[n] for n in seq_in])\n",
    "\n",
    "    seq_out = notes[i + SEQ_LEN]\n",
    "    data_y.append(note_to_int[seq_out])\n",
    "#end\n",
    "\n",
    "X = np.reshape(data_X, (len(data_X), SEQ_LEN, 1))\n",
    "X = X / float(len(notes))\n",
    "y = np_utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46965,
     "status": "ok",
     "timestamp": 1571556325039,
     "user": {
      "displayName": "Daniel Green",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCFRtqS5I7HVNdoY-OISy3BzinululKE6uTawrZ4g=s64",
      "userId": "17744463245578873670"
     },
     "user_tz": -60
    },
    "id": "m1t_oXso2R1Z",
    "outputId": "5da19d77-309c-4fd5-facf-b90b7e1f40fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8, 256)            264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5806)              1492142   \n",
      "=================================================================\n",
      "Total params: 2,281,646\n",
      "Trainable params: 2,281,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 890373,
     "status": "ok",
     "timestamp": 1571565573186,
     "user": {
      "displayName": "Daniel Green",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCFRtqS5I7HVNdoY-OISy3BzinululKE6uTawrZ4g=s64",
      "userId": "17744463245578873670"
     },
     "user_tz": -60
    },
    "id": "bnztGRBN4Lie",
    "outputId": "af22d4e8-f816-48d8-88c1-0ed3d67f8b1e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model_path = './raggen-model.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_path,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "use_existing_weights = True\n",
    "if use_existing_weights:\n",
    "      model.load_weights(model_path)\n",
    "\n",
    "should_train = False\n",
    "if should_train:\n",
    "    history = model.fit(X, y, epochs=50, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 890542,
     "status": "ok",
     "timestamp": 1571565573884,
     "user": {
      "displayName": "Daniel Green",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCFRtqS5I7HVNdoY-OISy3BzinululKE6uTawrZ4g=s64",
      "userId": "17744463245578873670"
     },
     "user_tz": -60
    },
    "id": "4u9snSO25XLs",
    "outputId": "7ff35bef-82e6-4cae-c286-2c6a1ecf69a5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3c695abb9206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# manually updated each time I run above\n",
    "total_epochs = 300\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Naive LSTM 1-1 Mapping Accuracy ({total_epochs} epochs total)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIfiCeYV5ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pattern: [599, 1751, 3866, 4536, 3062, 2354, 1694, 1385]\n"
     ]
    }
   ],
   "source": [
    "# reverse mapping\n",
    "int_to_note = dict((num, note) for num, note in enumerate(pitch_names))\n",
    "\n",
    "best_pred_only = False\n",
    "num_best_preds = 2\n",
    "\n",
    "# random start point\n",
    "start_idx = np.random.randint(0, len(data_X)-1)\n",
    "v1_pattern = data_X[start_idx]\n",
    "print(f'Starting pattern: {v1_pattern}')\n",
    "v1_output = []\n",
    "for idx in range(100 * SEQ_LEN):\n",
    "#     print(f'Pattern {idx}: {v1_pattern}')\n",
    "    prediction_input = np.reshape(v1_pattern, (1, len(v1_pattern), 1))\n",
    "    prediction_input = prediction_input / float(len(notes))\n",
    "    prediction = model.predict(prediction_input)\n",
    "    \n",
    "    if best_pred_only:\n",
    "        pred_idx = np.argmax(prediction[0])\n",
    "    else:\n",
    "        top_5_idx = np.argpartition(prediction[0], -num_best_preds)[-num_best_preds:]\n",
    "        pred_idx = top_5_idx[np.random.randint(0, len(top_5_idx))]\n",
    "    \n",
    "    result = int_to_note[pred_idx]\n",
    "    v1_output.append(result)\n",
    "\n",
    "#     print(f'\\tPredicted index: {pred_idx}')\n",
    "\n",
    "    v1_pattern.append(pred_idx)\n",
    "    v1_pattern = v1_pattern[1:len(v1_pattern)]\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 950, 8, 8, 2786, 3540, 8, 2662]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1571520919047,
     "user": {
      "displayName": "Daniel Green",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCFRtqS5I7HVNdoY-OISy3BzinululKE6uTawrZ4g=s64",
      "userId": "17744463245578873670"
     },
     "user_tz": -60
    },
    "id": "yGO4r9f9e4xM",
    "outputId": "c7d10b8b-7eac-486a-a080-2759bacce0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from music21 import stream, duration, key, meter, note, chord, instrument\n",
    "\n",
    "def split_note_duration(pattern):\n",
    "    n, d = pattern.split('$')\n",
    "    if '/' in d:\n",
    "        a, b = d.split('/')\n",
    "        d = float(a) / float(b)\n",
    "    else:\n",
    "        d = float(d)\n",
    "    #end\n",
    "    return n, d\n",
    "#end\n",
    "\n",
    "def notes_array_to_midi(notes_array):\n",
    "    offset = 0.0\n",
    "    output_notes = []\n",
    "    \n",
    "    for pattern in notes_array:\n",
    "#         print(pattern)\n",
    "        # handle chords (i.e. multiple notes split by NOTE_SEPARATOR)\n",
    "        if NOTE_SEPARATOR in pattern:\n",
    "            chord_notes = []\n",
    "            for chord_note in pattern.split(NOTE_SEPARATOR):\n",
    "                note_name, note_duration = split_note_duration(chord_note)\n",
    "                new_note = note.Note(note_name)\n",
    "                new_note.offset = offset\n",
    "                new_note.storedInstrument = instrument.Piano\n",
    "                new_note.duration = duration.Duration(note_duration)\n",
    "                output_notes.append(new_note)\n",
    "#                 chord_notes.append(new_note)\n",
    "            #end\n",
    "            new_chord = chord.Chord(chord_notes)\n",
    "            new_chord.offset = offset\n",
    "#             output_notes.append(new_chord)\n",
    "        #end\n",
    "        else:\n",
    "            note_name, note_duration = split_note_duration(pattern)\n",
    "            # handle rests\n",
    "            if REST_VALUE == note_name:\n",
    "                new_rest = note.Rest()\n",
    "                new_rest.offset = offset\n",
    "                new_rest.duration = duration.Duration(note_duration)\n",
    "                output_notes.append(new_rest)\n",
    "            else:\n",
    "                new_note = note.Note(note_name)\n",
    "                new_note.offset = offset\n",
    "                new_note.duration = duration.Duration(note_duration)\n",
    "                output_notes.append(new_note)\n",
    "        #end\n",
    "        \n",
    "        offset += TIMESTEP\n",
    "    #end\n",
    "    \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.timeSignature = meter.TimeSignature('2/4')\n",
    "    midi_stream.keySignature = key.KeySignature(0)\n",
    "    midi_stream.write('midi', fp='./output.mid')\n",
    "    return output_notes\n",
    "#end\n",
    "\n",
    "s = notes_array_to_midi(v1_output)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train-new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
